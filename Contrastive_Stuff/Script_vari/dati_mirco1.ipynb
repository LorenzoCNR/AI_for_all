{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c64e54-64cd-48e3-8345-148251505d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5cb12214-b450-4e71-88ba-fd54805f865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAssume a path structure:\\n\\nmain_folder\\n|___ data(folder)\\n|     |__project_data_folder1\\n                    |__ dati_cebra.jl (file dati)\\n      |__project_data_folder2\\n                    |__ dati_mirco.mat (file dati mat file, jle file etc)\\n|___ project_root(folder)\\n            |__d_cod_mon_Mirco.py\\n            |__some_functions.py\\n            |___EEG_ANN_pipeline(folder)\\n                    |__data (folder)\\n                    |__helpers (folder)\\n                    |__etc....\\n            |___output directory (folder)\\n            \\n\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Assume a path structure:\n",
    "\n",
    "main_folder\n",
    "|___ data(folder)\n",
    "|     |__project_data_folder1\n",
    "                    |__ dati_cebra.jl (file dati)\n",
    "      |__project_data_folder2\n",
    "                    |__ dati_mirco.mat (file dati mat file, jle file etc)\n",
    "|___ project_root(folder)\n",
    "            |__d_cod_mon_Mirco.py\n",
    "            |__some_functions.py\n",
    "            |___EEG_ANN_pipeline(folder)\n",
    "                    |__data (folder)\n",
    "                    |__helpers (folder)\n",
    "                    |__etc....\n",
    "            |___output directory (folder)\n",
    "            \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de45f93e-c55c-4329-b1e2-e186137f64f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\n"
     ]
    }
   ],
   "source": [
    "# need to declare:\n",
    "# 1) PROJECT root directory\n",
    "#  windows directories\n",
    "i_dir='J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff'\n",
    "\n",
    "#  ubuntu directories\n",
    "#i_dir=r'/media/zlollo/21DB-AB79/AI_PhD_Neuro_CNR/Empirics/GIT_stuff/AI_for_all/Contrastive_Stuff/'\n",
    "\n",
    "os.chdir(i_dir)\n",
    "print(os.getcwd())\n",
    "from some_functions import *\n",
    "# 2) NAME of folder containing data (input) directory. \n",
    "data_dir=\"data\"\n",
    "# (specific) project data folder\n",
    "sub_data=\"Monkeys_Mirco\"\n",
    "\n",
    "# 3) PIPELINE folder name\n",
    "pipe_path= \"EEG-ANN-Pipeline\"\n",
    "\n",
    "# 4) OUTPUT folder: folder to store processed output\n",
    "#    (if not existing is created)\n",
    "out_dir=\"contrastive_output\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c03ad55-60f7-489a-88d2-b1621060de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:some_functions:Project root resolved to: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\n",
      "INFO:some_functions:Path to 'EEG-ANN-Pipeline': J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\EEG-ANN-Pipeline\n",
      "INFO:some_functions:Input data path: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\data\\Monkeys_Mirco\n",
      "INFO:some_functions:Output path: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\contrastive_output\n",
      "INFO:some_functions:Added 'J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\EEG-ANN-Pipeline' to sys.path\n",
      "INFO:some_functions:Output directory ensured: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\contrastive_output\n"
     ]
    }
   ],
   "source": [
    "# Load path(s)\n",
    "project_root, eeg_pipeline_path, default_output_dir, default_input_dir = setup_paths( data_dir,sub_data,out_dir, pipe_path,change_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac7b75b-d0df-479c-b88a-0f13eac8ea5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco',\n",
       " 'C:\\\\Users\\\\loren\\\\Desktop\\\\Shared\\\\Società\\\\Outerrim\\\\Elaborazione DS Desktop\\\\dati',\n",
       " 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco\\\\ C:\\\\Users\\\\loren\\\\models\\\\research\\\\lfads',\n",
       " 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco\\\\ C:\\\\Users\\\\loren\\\\lfads-run-manager\\\\src',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\python311.zip',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin',\n",
       " 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\EEG-ANN-Pipeline']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b65c33-763b-4558-b8fc-31589f51a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "from data import LabelsDistance, TrialEEG, DatasetEEG, DatasetEEGTorch\n",
    "from data.preprocessing import normalize_signals\n",
    "from models import EncoderContrastiveWeights\n",
    "from helpers.model_utils import plot_training_metrics, count_model_parameters, train_model\n",
    "from helpers.visualization import plot_latent_trajectories_3d, plot_latents_3d\n",
    "from helpers.distance_functions import *\n",
    "from layers.custom_layers import _Skip, Squeeze, _Norm, _MeanAndConv\n",
    "# \n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "import sklearn.metrics\n",
    "import joblib as jl\n",
    "import seaborn as sns# \n",
    "# \n",
    "from cebra import CEBRA\n",
    "import cebra\n",
    "from some_functions import *\n",
    "# \n",
    "import matplotlib\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "# Random Seeds\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config GPU\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04b29d96-97dd-43cd-a12c-cfe42ce51880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco', 'C:\\\\Users\\\\loren\\\\Desktop\\\\Shared\\\\Società\\\\Outerrim\\\\Elaborazione DS Desktop\\\\dati', 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco\\\\ C:\\\\Users\\\\loren\\\\models\\\\research\\\\lfads', 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\dati_Mirco\\\\ C:\\\\Users\\\\loren\\\\lfads-run-manager\\\\src', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\python311.zip', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib', 'C:\\\\Users\\\\loren\\\\anaconda3', '', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\loren\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin', 'J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff\\\\EEG-ANN-Pipeline']\n",
      "daje\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)\n",
    "\n",
    "if 'torch' in sys.modules:\n",
    "    print('daje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4df79e-807b-4579-aeaa-4367ae8ba968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef build_model(filters, dropout, latents, num_timepoints, chns):\\n    \\n    return nn.Sequential(\\n        nn.Conv2d(1, filters, kernel_size=(1, num_timepoints)),\\n        nn.BatchNorm2d(filters),\\n        nn.Conv2d(filters, filters, kernel_size=(chns, 1), groups=filters),\\n        nn.BatchNorm2d(filters),\\n        nn.Dropout(dropout),\\n        nn.Flatten(),\\n        nn.Linear(filters, filters),\\n        nn.SELU(),\\n        nn.Dropout(dropout),\\n        nn.Linear(filters, latents)\\n    )\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# BUILD the model encoder. (1: cnnd1d simil cebra with skip connections)\n",
    "def build_model(filters, dropout, latents, num_timepoints, chns, num_units=None, groups=1,normalize=True):\n",
    "    \"\"\"\n",
    "    Build a cnn1d model with:\n",
    "    - chns: Input channels.\n",
    "    - filters: convolutional layer(s) filters.\n",
    "    - latents: outpuit dimension (latent space).\n",
    "    - num_timepoints: window dimension (test the optimal one).\n",
    "    - dropout:  dropout.\n",
    "    - num_units: optional intermediate filters.\n",
    "    \"\"\"\n",
    "    if num_units is None:\n",
    "        num_units = filters \n",
    "    layers = [\n",
    "        Squeeze(),\n",
    "        nn.Conv1d(chns, filters, kernel_size=2),\n",
    "        nn.GELU(),\n",
    "        _Skip(nn.Conv1d(filters, filters, kernel_size=3), nn.GELU()),\n",
    "        _Skip(nn.Conv1d(filters, filters, kernel_size=3), nn.GELU()),\n",
    "        _Skip(nn.Conv1d(filters, filters, kernel_size=3), nn.GELU()),\n",
    "        nn.Conv1d(filters, latents, kernel_size=3),\n",
    "    ]\n",
    "\n",
    "    if normalize:\n",
    "        layers.append(_Norm())  #\n",
    "\n",
    "    layers.extend([\n",
    "        nn.Flatten(),  # \n",
    "        #nn.Dropout(dropout),  # \n",
    "    ])\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "#### Build the model encoder (2: cnn2d)\n",
    "# \n",
    "'''\n",
    "def build_model(filters, dropout, latents, num_timepoints, chns):\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, filters, kernel_size=(1, num_timepoints)),\n",
    "        nn.BatchNorm2d(filters),\n",
    "        nn.Conv2d(filters, filters, kernel_size=(chns, 1), groups=filters),\n",
    "        nn.BatchNorm2d(filters),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(filters, filters),\n",
    "        nn.SELU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(filters, latents)\n",
    "    )\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe728c64-ba8c-436b-94e0-026e568d10e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n- Minkowski Distance: A generalized distance metric that includes \\n    both Euclidean (p=2) and Manhattan (p=1) distances as special cases. \\n\\n- Adaptive Gaussian Distance**:\\n- Direction Distance\\n\\n- Circular Distance\\n\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  DEFINE DISTANCES to compute the loss (In   some_functions module)\n",
    "\"\"\"\n",
    "\n",
    "- Minkowski Distance: A generalized distance metric that includes \n",
    "    both Euclidean (p=2) and Manhattan (p=1) distances as special cases. \n",
    "\n",
    "- Adaptive Gaussian Distance**:\n",
    "- Direction Distance\n",
    "\n",
    "- Circular Distance\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5117e617-ef51-48b8-901b-ea5e3cf15631",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#### PARAMETERS ###\n",
    "## sampling frequency (ms)    \n",
    "fs = 1000\n",
    "## Validation/test split\n",
    "valid_split = 0.15\n",
    "## window of each mini batch\n",
    "ww = 10\n",
    "# overlap\n",
    "shift = 1\n",
    "#\n",
    "dropout = 0.5\n",
    "## temperature\n",
    "tau = 0.5\n",
    "## network hidden layers channles\n",
    "filters = 16\n",
    "## output channels (latents)\n",
    "latents = 3\n",
    "# learning rate\n",
    "l_rate = 0.0001\n",
    "#\n",
    "epochs = 100\n",
    "#sigma_pos = 0.016\n",
    "#sigma_time = 0.025\n",
    "#\n",
    "batch_size=1024\n",
    "#\n",
    "num_units = filters\n",
    "#\n",
    "normalize=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a84e24f5-ac20-4fc3-81d9-ef364a86cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to load: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\data\\Monkeys_Mirco\\dati_mirco.mat\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# recall the input dir (declared upwards) and import data\n",
    "input_dir = default_input_dir\n",
    "# data format\n",
    "d_format=\"mat\"\n",
    "# data_name\n",
    "d_name='dati_mirco'\n",
    "data = load_data(input_dir, d_name,d_format)\n",
    "print(type(data)) # must be a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "427bd2f4-033e-41c3-bbeb-b8c6882e11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### define X ed Y\n",
    "'''\n",
    "Get the data from the imported  dictionary\n",
    "Data Structure:\n",
    "   - X (neural data) is a matrix T(ime)xch(annels)\n",
    "   - y_... are the associated labels, which can be:\n",
    "    Discrete or continuous.\n",
    "    Either matrices or vectors with dimensions T×n, meaning:\n",
    "        Labels exist for each time point.\n",
    "        n is the number of label dimensions.\n",
    "\n",
    "\n",
    "'''\n",
    "X=data['m1_active_neural']\n",
    "y_dir=data['m1_active_trial']\n",
    "y_dir=y_dir.flatten()\n",
    "y_pos=data['m1_active_pos']\n",
    "#y_pos=y_pos.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff974104-eae7-4a18-afab-3649414d7573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao\n"
     ]
    }
   ],
   "source": [
    "# IDENTIFY Trials (info should  be in the data dictionary or should be derived somehow\n",
    "# i.e. every change in y_dir value - direction label - \n",
    "# tipo dove y_dir cambia...with the caution that it might not change from one trial to another).\n",
    "\n",
    "trial_id=data['m1_active_trial_id']\n",
    "trial_id=trial_id.flatten()\n",
    "#n_trials_=127\n",
    "len_y=len(y_dir)\n",
    "change_idx = np.where(np.diff(trial_id) != 0)[0] + 1\n",
    "change_idx\n",
    "print('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32669846-4cb3-4cd0-bf2f-acbdb7b7e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# the c_t vector tells the starting and endiing points of every trial\n",
    "c_t=np.concatenate([[0], change_idx,[len_y]], dtype=int)\n",
    "n_trials=len(c_t)-1\n",
    "### check trial length (useful for graphics)\n",
    "trial_len=np.diff(c_t)\n",
    "\n",
    "# zero variance = fix (constant) length (this info will be used for plots)\n",
    "if np.var(trial_len)==0:    \n",
    "    constant_len=True\n",
    "else:\n",
    "    constant_len=False\n",
    "print(constant_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1391c67-92f0-4a6e-b70d-a3c7ae6cb1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "####  Number of channels Either first (0) or second dimension (1)\n",
    "chns = X.shape[1]\n",
    "print(chns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27f1f1c3-62db-4266-aff1-c7a2e722d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esplorazione dell'oggetto: TrialEEG\n",
      "--------------------------------------------------\n",
      "eeg_signals: array shape (3, 1500)\n",
      "labels: {'position': array([[ 0.6      ,  0.6      ,  0.6      , ...,  6.5      ,  6.5      ,\n",
      "         6.5      ],\n",
      "       [-1.1711303, -1.1441596, -1.1250274, ..., -5.575    , -5.575    ,\n",
      "        -5.575    ]], dtype=float32), 'direction': array([4., 4., 4., ..., 4., 4., 4.], dtype=float32)}\n",
      "num_channels: 3\n",
      "num_timepoints: 1500\n",
      "plot: <bound method TrialEEG.plot of <data.eeg_dataset.TrialEEG object at 0x00000171F58F4C90>>\n",
      "timepoints: array shape (1500,)\n",
      "--------------------------------------------------\n",
      "Labels type in __str__: multi_label\n",
      "num_trials               :  41\n",
      "num_channels (per trial) :  3\n",
      "timepoints (per trial)   :  1500 (fix)\n",
      "labels_type              :  multi_label\n",
      "labels_format            :  {'position': 'ndarray', 'direction': 'ndarray'}\n",
      "\n",
      "Numero canali = 3, numero timepoints = 1500\n",
      "Istante iniziale = 1.5, tempo finale = 3.0\n",
      "Labels:\n",
      "  position: shape (2, 1500)\n",
      "  direction: shape (1500,)\n",
      "Esplorazione dell'oggetto: TrialEEG\n",
      "--------------------------------------------------\n",
      "eeg_signals: array shape (3, 1500)\n",
      "labels: {'position': array([[ 0.5       ,  0.5       ,  0.4944614 , ...,  2.325     ,\n",
      "         2.325     ,  2.3417134 ],\n",
      "       [-0.8999999 , -0.9120426 , -0.91946137, ...,  8.000392  ,\n",
      "         8.022484  ,  8.043095  ]], dtype=float32), 'direction': array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)}\n",
      "num_channels: 3\n",
      "num_timepoints: 1500\n",
      "plot: <bound method TrialEEG.plot of <data.eeg_dataset.TrialEEG object at 0x00000171F58A2C90>>\n",
      "timepoints: array shape (1500,)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## CREATE TRIALS adding the behavioral info we want ########\n",
    "'''\n",
    " trial_ids is a vector telling us the trial at time t\n",
    " c_t tells us starting (and ending) point of each trial \n",
    "'''\n",
    "\n",
    "trials = [\n",
    "    TrialEEG(\n",
    "       X[ c_t[i]:c_t[i+1]].T,  # Segnali EEG\n",
    "          # Labels\n",
    "          [(\n",
    "             'position', y_pos[c_t[i]:c_t[i+1]].T),\n",
    "           ( 'direction',y_dir[c_t[i]:c_t[i+1]].T,          \n",
    "       ) ],\n",
    "          # Timepoints\n",
    "        np.linspace(c_t[i] / fs, c_t[i+1] / fs, c_t[i+1] - c_t[i])  \n",
    "    )\n",
    "    for i in range(len(c_t) - 1)\n",
    "]\n",
    "\n",
    "## check\n",
    "explore_obj(trials[5])\n",
    "dataset = DatasetEEG(trials)\n",
    "print(dataset)\n",
    "print(dataset.trials[1])\n",
    "explore_obj(dataset.trials[1])\n",
    "dataset.trials[0].eeg_signals[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e7f3fc6-4999-4372-8739-250f192f4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to generate embeddings after data processing \n",
    "# (move to some_functions after generalizing for the labels)\n",
    "def generate_embeddings(model, dataset_pytorch, batch_size, device):\n",
    "    model.eval()\n",
    "    ## \n",
    "    z, labels_position, labels_direction = [], [],[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, dataset_pytorch.num_trials, batch_size):\n",
    "            x = dataset_pytorch.eeg_signals[i:i+batch_size].to(device)\n",
    "            l_pos = dataset_pytorch.labels['position'][i:i+batch_size,:]\n",
    "            l_dir = dataset_pytorch.labels['direction'][i:i+batch_size]\n",
    "            print(l_dir)\n",
    "            f_x = model(x)\n",
    "\n",
    "            z.append(f_x.cpu().numpy())\n",
    "            labels_position.append(l_pos.cpu().numpy())\n",
    "            labels_direction.append(l_dir.cpu().numpy().reshape(-1))\n",
    "\n",
    "    z = np.concatenate(z)\n",
    "    labels_position = np.concatenate(labels_position)\n",
    "    labels_direction = np.concatenate(labels_direction)\n",
    " \n",
    "    return z ,labels_direction, labels_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "378d9580-7f0d-4fa6-93d1-8260cc350005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels type in __str__: multi_label\n",
      "num_trials               :  61090\n",
      "num_channels (per trial) :  3\n",
      "timepoints (per trial)   :  10 (fix)\n",
      "labels_type              :  multi_label\n",
      "labels_format            :  {'position': 'ndarray', 'direction': 'ndarray'}\n",
      "\n",
      "Esplorazione dell'oggetto: TrialEEG\n",
      "--------------------------------------------------\n",
      "eeg_signals: array shape (3, 10)\n",
      "labels: {'position': array([ 0.15      , -0.28761515], dtype=float32), 'direction': array(8., dtype=float32)}\n",
      "num_channels: 3\n",
      "num_timepoints: 10\n",
      "plot: <bound method TrialEEG.plot of <data.eeg_dataset.TrialEEG object at 0x00000171F92DD550>>\n",
      "timepoints: array shape (10,)\n",
      "--------------------------------------------------\n",
      "{'position': 'ndarray', 'direction': 'ndarray'}\n",
      "Esplorazione dell'oggetto: DatasetEEGTorch\n",
      "--------------------------------------------------\n",
      "_is_protocol: False\n",
      "create_labels: <bound method DatasetEEGTorch.create_labels of <data.eeg_dataset_torch.DatasetEEGTorch object at 0x00000171F5900490>>\n",
      "Labels type in __str__: multi_label\n",
      "dataset_original: num_trials               :  61090\n",
      "num_channels (per trial) :  3\n",
      "timepoints (per trial)   :  10 (fix)\n",
      "labels_type              :  multi_label\n",
      "labels_format            :  {'position': 'ndarray', 'direction': 'ndarray'}\n",
      "\n",
      "eeg_signals: shape torch.Size([61090, 1, 3, 10])\n",
      "label_names: length 2\n",
      "labels: {'position': tensor([[ 0.3000, -0.9750],\n",
      "        [ 0.3018, -0.9750],\n",
      "        [ 0.3254, -0.9750],\n",
      "        ...,\n",
      "        [-0.8750,  6.0700],\n",
      "        [-0.8750,  6.0496],\n",
      "        [-0.8750,  6.0292]]), 'direction': tensor([3., 3., 3.,  ..., 1., 1., 1.])}\n",
      "labels_format: {'position': 'ndarray', 'direction': 'ndarray'}\n",
      "labels_type: multi_label\n",
      "num_channels: 3\n",
      "num_timepoints: 10\n",
      "num_trials: 61090\n",
      "to_device: <bound method DatasetEEGTorch.to_device of <data.eeg_dataset_torch.DatasetEEGTorch object at 0x00000171F5900490>>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "############# FULL DATASET (No training/test/validation split) ################\n",
    "'''\n",
    "split dataset into windows (these are the elements going in the batches)\n",
    "    ww: mini-sample dimension\n",
    "    shift: window overlap (shift=1 means sampling 1-10, 2-11, 3-12...)\n",
    "'''\n",
    "### \n",
    "dataset_windows=dataset.create_windows(ww, shift)\n",
    "print(dataset_windows)\n",
    "# check\n",
    "explore_obj(dataset_windows.trials[46464])\n",
    "\n",
    "#### Convert to PyTorch datasets\n",
    "# if u need to select some particular labels\n",
    "#sel_lab='position' (optional argument for the next called function)\n",
    "\n",
    "dataset_pytorch=DatasetEEGTorch(dataset_windows)\n",
    "explore_obj(dataset_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1381744a-8832-407a-9afa-8929ac5d0fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esplorazione dell'oggetto: LabelsDistance\n",
      "--------------------------------------------------\n",
      "get_weights: <bound method LabelsDistance.get_weights of <data.contrastive_sampling.LabelsDistance object at 0x00000171F3977210>>\n",
      "label_keys: length 1\n",
      "labels_distance_functions: {'position': <function adaptive_gaussian_distance at 0x00000171F58C71A0>}\n",
      "multi_label: False\n",
      "--------------------------------------------------\n",
      "<class 'list'>\n",
      "[tensor([[[[    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0001,\n",
      "               -0.0000,     -0.0001],\n",
      "          [    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000],\n",
      "          [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "        [[[    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0001,     -0.0001],\n",
      "          [    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000],\n",
      "          [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,      0.0000]]],\n",
      "\n",
      "\n",
      "        [[[    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0001,\n",
      "               -0.0001,     -0.0000],\n",
      "          [    -0.0000,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000],\n",
      "          [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,     -0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,      0.0000],\n",
      "          [     0.0000,     -0.0000,     -0.0001,  ...,      0.0001,\n",
      "                0.0001,      0.0001],\n",
      "          [    -0.0000,     -0.0000,      0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,      0.0000],\n",
      "          [    -0.0000,     -0.0001,     -0.0001,  ...,      0.0001,\n",
      "                0.0001,      0.0001],\n",
      "          [    -0.0000,      0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
      "                0.0000,      0.0000],\n",
      "          [    -0.0001,     -0.0001,     -0.0001,  ...,      0.0001,\n",
      "                0.0001,      0.0001],\n",
      "          [     0.0000,     -0.0000,     -0.0000,  ...,     -0.0000,\n",
      "               -0.0000,     -0.0000]]]], device='cuda:0'), {'position': tensor([[ 0.3000, -0.9750],\n",
      "        [ 0.3018, -0.9750],\n",
      "        [ 0.3254, -0.9750],\n",
      "        ...,\n",
      "        [-0.6250, -1.0748],\n",
      "        [-0.6035, -1.0750],\n",
      "        [-0.6000, -1.0750]], device='cuda:0'), 'direction': tensor([3., 3., 3.,  ..., 3., 3., 3.], device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Define label distances...multi label must be a dictionary; single label can \n",
    "be  either a function or a dictionary with one element\n",
    " 'direction': direction_distance\n",
    "  'position':adaptive_gaussian_distance..\n",
    "\n",
    "the following line includes both position and direction distancethat is both \n",
    "lables will be used during training\n",
    "***labels_distance = LabelsDistance({'position': adaptive_gaussian_distance,'direction':direction_distance})\n",
    "\n",
    "the following line only includes direction distance in the process\n",
    "***labels_distance = LabelsDistance({'position': adaptive_gaussian_distance})\n",
    "\n",
    "'''\n",
    "#labels_distance = LabelsDistance({'direction':direction_distance})\n",
    "labels_distance = LabelsDistance({'position': adaptive_gaussian_distance})\n",
    "\n",
    "explore_obj(labels_distance)\n",
    "## deliver to cuda devices (if any available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_pytorch.to_device(device)\n",
    "device\n",
    "batch_size=1024\n",
    "\n",
    "dataloader_ = DataLoader(dataset_pytorch, batch_size=batch_size, shuffle=False)\n",
    "## explore the dataloader\n",
    "for batch in dataloader_:\n",
    "    #►pippo.append(batch)\n",
    "    print(type(batch)) \n",
    "    print(batch)       \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83f2d498-37a3-4a73-858a-46d3b2c76a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: EncoderContrastiveWeights(\n",
      "  (layers): Sequential(\n",
      "    (0): Squeeze()\n",
      "    (1): Conv1d(3, 32, kernel_size=(2,), stride=(1,))\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (4): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (5): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (6): Conv1d(32, 3, kernel_size=(3,), stride=(1,))\n",
      "    (7): _Norm()\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "Model has 9828 parameters.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Build and train the model\n",
    "# update the weights according the chosen labels (same value, same weight)\n",
    "# just one value for label\n",
    "\n",
    "from data import LabelsDistance, TrialEEG, DatasetEEG, DatasetEEGTorch\n",
    "from data.preprocessing import normalize_signals\n",
    "from models import EncoderContrastiveWeights\n",
    "filters=32\n",
    "num_units=filters\n",
    "epochs=300\n",
    "\n",
    "model = EncoderContrastiveWeights(\n",
    "    ### define the network (recall the parameters defined from line 209)\n",
    "    layers=build_model(filters, dropout, latents, ww, chns, normalize=normalize),\n",
    "    ### choose between infoNCE, supervised contrastive, weeighted contrastive loss\n",
    "    #loss_type=\"weighted_contrastive\",\n",
    "    # \n",
    "    labels_distance=labels_distance,\n",
    "    #labels_distance=None,\n",
    "    ## If we use the labels, choose some weights\n",
    "    ## if we have more label and want a different weight for every label\n",
    "    ## just put a weight for each label; if we have one label or want just the \n",
    "    ## same weight for each label one value is ok\n",
    "    labels_weights=[0.5],\n",
    "    #labels_weights=None,\n",
    "    temperature=tau,\n",
    "    train_temperature=False,\n",
    "    ### time contrastive loss asks either offset or window\n",
    "    #positive_offset=5,  # Offset per i positivi (se usi offset)\n",
    "    #positive_window=0 \n",
    "    \n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model architecture:\", model)\n",
    "print(f\"Model has {count_model_parameters(model)} parameters.\")\n",
    "#print(f\"subject is {name}\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f52a32c0-a069-44ad-8f64-a2df61211946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: EncoderContrastiveWeights(\n",
      "  (layers): Sequential(\n",
      "    (0): Squeeze()\n",
      "    (1): Conv1d(3, 32, kernel_size=(2,), stride=(1,))\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (4): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (5): _Skip(\n",
      "      (module): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "        (1): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (6): Conv1d(32, 3, kernel_size=(3,), stride=(1,))\n",
      "    (7): _Norm()\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "Model has 9828 parameters.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from data import LabelsDistance, TrialEEG, DatasetEEG, DatasetEEGTorch\n",
    "from data.preprocessing import normalize_signals\n",
    "from models import EncoderContrastiveWeights\n",
    "filters=32\n",
    "num_units=filters\n",
    "epochs=300\n",
    "\n",
    "model = EncoderContrastiveWeights(\n",
    "    ### define the network (recall the parameters defined from line 209)\n",
    "    layers=build_model(filters, dropout, latents, ww, chns, normalize=normalize),\n",
    "    ### choose between infoNCE, supervised contrastive, weeighted contrastive loss\n",
    "    #loss_type=\"weighted_contrastive\",\n",
    "    # \n",
    "    labels_distance=labels_distance,\n",
    "    #labels_distance=None,\n",
    "    ## If we use the labels, choose some weights\n",
    "    ## if we have more label and want a different weight for every label\n",
    "    ## just put a weight for each label; if we have one label or want just the \n",
    "    ## same weight for each label one value is ok\n",
    "    labels_weights=[0.5],\n",
    "    #labels_weights=None,\n",
    "    temperature=tau,\n",
    "    train_temperature=False,\n",
    "    ### time contrastive loss asks either offset or window\n",
    "    #positive_offset=5,  # Offset per i positivi (se usi offset)\n",
    "    #positive_window=0 \n",
    "    \n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model architecture:\", model)\n",
    "print(f\"Model has {count_model_parameters(model)} parameters.\")\n",
    "#print(f\"subject is {name}\")\n",
    "print(f\"{device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f53697-0eba-4fdb-8b92-06d3866d9ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████▎   | 268/300 [04:27<00:32,  1.02s/it, alignement=-4.66, uniformity=4.44, loss=-.22]"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=l_rate)\n",
    "\n",
    "# train on a batch (just to check if everything is ok)\n",
    "batch = next(iter(dataloader_))\n",
    "loss_dict = model.process_batch(batch, optimizer)\n",
    "\n",
    "### model training\n",
    "metrics = train_model(model, optimizer, dataloader_, epochs=epochs)\n",
    "plot_training_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "478ec438-22fb-4b1d-b665-1e341dd7eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 8., 8., 8.], device='cuda:0')\n",
      "tensor([8., 8., 8.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 8., 8., 8.], device='cuda:0')\n",
      "tensor([8., 8., 8.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 8., 8., 8.], device='cuda:0')\n",
      "tensor([8., 8., 8.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 8., 8., 8.], device='cuda:0')\n",
      "tensor([8., 8., 8.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 4., 4., 4.], device='cuda:0')\n",
      "tensor([4., 4., 4.,  ..., 2., 2., 2.], device='cuda:0')\n",
      "tensor([2., 2., 2.,  ..., 6., 6., 6.], device='cuda:0')\n",
      "tensor([6., 6., 6.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 3., 3., 3.], device='cuda:0')\n",
      "tensor([3., 3., 3.,  ..., 8., 8., 8.], device='cuda:0')\n",
      "tensor([8., 8., 8.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 7., 7., 7.], device='cuda:0')\n",
      "tensor([7., 7., 7.,  ..., 5., 5., 5.], device='cuda:0')\n",
      "tensor([5., 5., 5.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## GENERATE EMBEDDINGS and recover the label info \n",
    "z_0, l_dir_0, l_pos_0 = generate_embeddings(model, dataset_pytorch, batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6adb0324-081e-4134-ad79-7e00c2e6b393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "       1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "       1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "       1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d66b3fcf-964a-422b-8557-1c4d7290c7f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_direction_averaged_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m c_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaroon\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m default_output_dir\n\u001b[1;32m---> 14\u001b[0m plot_direction_averaged_embedding(z_0, l_dir_0, n_traj,c_s,output_folder, \n\u001b[0;32m     15\u001b[0m                                       trial_len, constant_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m     16\u001b[0m                                       ww\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_direction_averaged_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "from some_functions import *\n",
    "### generate 3d plot\n",
    "trial_length=trial_len[0]\n",
    "constant_len\n",
    "###define the trajectories. First monkey is 1-8, second is 9-16\n",
    "# first\n",
    "n_traj=np.arange(8)+1\n",
    "# second\n",
    "#n_traj=np.arange(8)+9\n",
    "#\n",
    "\n",
    "c_s=\"maroon\"\n",
    "output_folder = default_output_dir\n",
    "plot_direction_averaged_embedding(z_0, l_dir_0, n_traj,c_s,output_folder, \n",
    "                                      trial_len, constant_length=True, \n",
    "                                      ww=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92b75d75-248e-4a7d-89bb-c5f76a7aa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from some_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d19d89-9283-4f2a-bc27-426360e71564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
