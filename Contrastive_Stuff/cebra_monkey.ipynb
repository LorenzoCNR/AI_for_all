{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79275b5c-1a66-4be4-9944-9066a4004373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import logging\n",
    "import mimetypes\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "### load path (use the function in module some functions)\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "#import shap\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import warnings\n",
    "import logging\n",
    "#import umap \n",
    "import openTSNE\n",
    "import random\n",
    "import typing\n",
    "import joblib as jl\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split,  ParameterSampler, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "import sklearn.metrics\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import cebra.datasets\n",
    "from cebra import CEBRA\n",
    "from cebra  import *\n",
    "from scipy import optimize as opt\n",
    "from cebra.datasets.hippocampus import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2c3d1f-6fbe-43ee-86f8-8d25fa6f8ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:some_functions:Project root resolved to: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\n",
      "INFO:some_functions:Path to 'EEG-ANN-Pipeline': J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\EEG-ANN-Pipeline\n",
      "INFO:some_functions:Input data path: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\data\\Monkeys_Mirco\n",
      "INFO:some_functions:Output path: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\contrastive_output\n",
      "INFO:some_functions:Added 'J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\EEG-ANN-Pipeline' to sys.path\n",
      "INFO:some_functions:Output directory ensured: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\Contrastive_Stuff\\contrastive_output\n"
     ]
    }
   ],
   "source": [
    "# DECLARE \n",
    "# 1) PROJECT root directory\n",
    "#  windows directories\n",
    "i_dir='J:\\\\AI_PhD_Neuro_CNR\\\\Empirics\\\\GIT_stuff\\\\AI_for_all\\\\Contrastive_Stuff'\n",
    "\n",
    "#  ubuntu directories\n",
    "#i_dir=r'/media/zlollo/21DB-AB79/AI_PhD_Neuro_CNR/Empirics/GIT_stuff/AI_for_all/Contrastive_Stuff/'\n",
    "\n",
    "os.chdir(i_dir)\n",
    "os.getcwd()\n",
    "from some_functions import *\n",
    "from model_utils import *\n",
    "\n",
    "# Random Seeds\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config GPU\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# 2) NAME of folder containing data (input) directory. \n",
    "data_dir=\"data\"\n",
    "# (specific) project data folder\n",
    "sub_data=\"Monkeys_Mirco\"\n",
    "\n",
    "# 3) PIPELINE folder name\n",
    "pipe_path= \"EEG-ANN-Pipeline\"\n",
    "\n",
    "# 4) OUTPUT folder: folder to store processed output\n",
    "#    (if not existing is created)\n",
    "out_dir=\"contrastive_output\"\n",
    "\n",
    "project_root, eeg_pipeline_path, default_output_dir, default_input_dir = setup_paths( data_dir,sub_data,out_dir, pipe_path,change_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a41e35-bd51-454c-9289-c9b18cb5a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to load: J:\\AI_PhD_Neuro_CNR\\Empirics\\GIT_stuff\\AI_for_all\\data\\Monkeys_Mirco\\dati_mirco_18_03_k.mat\n",
      "<class 'dict'>\n",
      "ciao\n"
     ]
    }
   ],
   "source": [
    "# recall the input dir (declared upwards) and import data\n",
    "input_dir = default_input_dir\n",
    "# data format\n",
    "d_format=\"mat\"\n",
    "# data_name \n",
    "d_name='dati_mirco_18_03_k'\n",
    "data = load_data(input_dir, d_name,d_format)\n",
    "print(type(data)) # must be a dictionary\n",
    "\n",
    "X=data['k_cond2_active_neural']\n",
    "y_dir=data['k_cond2_active_trial']\n",
    "y_dir=y_dir.flatten()\n",
    "#y_pos=data['mix_active_trial']\n",
    "trial_id=data['k_cond2_active_trial_id']\n",
    "trial_id=trial_id.flatten()\n",
    "len_y=len(y_dir)\n",
    "change_idx = np.where(np.diff(trial_id) != 0)[0] + 1\n",
    "change_idx\n",
    "print('ciao')\n",
    "# the c_t vector tells the starting and endiing points of every trial\n",
    "c_t=np.concatenate([[0], change_idx,[len_y]], dtype=int)\n",
    "## list of list of starting and ending points for trials\n",
    "c_t_list=[]\n",
    "c_t_list = [(c_t[i], c_t[i+1] - 1) for i in range(len(c_t) - 1)]\n",
    "n_trials=len(c_t)-1\n",
    "\n",
    "### check trial length (useful for graphics)\n",
    "trial_len=np.diff(c_t)\n",
    "trial_length=trial_len[0]\n",
    "original_label_order = np.arange(1, 9)  # [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc9f573-5fe6-4f59-9ab3-50f8c5af0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### RESAMPLING ########################################\n",
    "\n",
    "##### option to resample data a different frequency \n",
    "#### RESAMPLIGN DATA FUNCTION\n",
    "#for start_trial, end_trial in c_t_list:\n",
    "    #print(start_trial, end_trial)\n",
    "\n",
    "### choose resampling method according to variable type\n",
    "methods = {\n",
    "    0: \"sum\",  \n",
    "    1: \"center\"  \n",
    "    #,2: \"mean\"\n",
    "}\n",
    "\n",
    "## data to resample\n",
    "l_data=[X,y_dir] \n",
    "step=10\n",
    "overlap=6\n",
    "Normalize=True\n",
    "### resampled data, new trials lengths, new trials intervals\n",
    "resampled,r_trial_lengths,r_trial_indices =  f_resample(l_data,c_t_list, step,\n",
    "                       overlap, methods, mode=\"overlapping\",normalization=True)\n",
    "\n",
    "## new Trials' intervals\n",
    "r_trial=r_trial_indices[0]\n",
    "start_points=[]\n",
    "start_points = [x[0] for x in r_trial] + [r_trial[-1][1] + 1]\n",
    "\n",
    "c_t_resampled=np.array(start_points).flatten()\n",
    "\n",
    "r_trial_indices[0][1][0]\n",
    "unique_labels = np.unique(resampled[1])\n",
    "\n",
    "\n",
    "### Swapping option\n",
    "### ricampionamento e permutazione delle labels ###\n",
    "### 6-3, 3-6\n",
    "#swap_dict = {3: 6, 6: 3}\n",
    "# Apply mapping back to restore original labels (optional)\n",
    "#resampled_swapped = swap_labels(resampled[1], swap_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd602d5-d06a-41fc-848b-a8fa510b6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## when picking resampled  data ##########################\n",
    "X_=resampled[0]\n",
    "len_labs=len(X_)\n",
    "y_dir_=resampled[1].reshape(len_labs,1).astype(int)\n",
    "trial_length=r_trial_lengths[0][0]\n",
    "\n",
    "################ when picking original data ###########################\n",
    "#X_=X\n",
    "#len_labs=len(X_)\n",
    "#y_dir_=y_dir.reshape(len_labs,1).astype(int)\n",
    "#♠trial_length=trial_len[0]\n",
    "\n",
    "############## if we want to create a time variable to augment the label info\n",
    "#y_time_=list(np.arange(1,trial_length+1))*n_trials\n",
    "#y_time_=np.array(y_time_).reshape(len_labs,1).astype(float)\n",
    "\n",
    "#yy_=np.concatenate((y_dir_,y_time_),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ab0fb9-7e29-44a2-b22c-dd4bd8ca8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7860 neg:  7.0837 total:  6.2977 temperature:  1.2660: 100%|██████████| 20000/20000 [02:33<00:00, 130.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################### MODEL PART ##############################\n",
    "################## model data\n",
    "### neural data and direction labels\n",
    "### with no resampling just pick X and y_dir\n",
    "\n",
    "data_={\"X\":X_,\"y\":y_dir_}\n",
    "\n",
    "train_data_=['X', 'y']\n",
    "# neural data (full sample)\n",
    "transform_data_=['X']\n",
    "#from cebra.sklearn.metrics import infonce_loss\n",
    "param_file='model_params_1.yaml'\n",
    "params_path = Path(project_root) / param_file\n",
    "params = load_params(params_path)\n",
    "\n",
    "## define the model and declare the data u want to use\n",
    "model_type='cebra_behavior'\n",
    "\n",
    "fixed_params = params[model_type]['fixed']\n",
    "\n",
    "model_params = {**fixed_params}\n",
    "model_params\n",
    "\n",
    "     #######\n",
    "## you can change whatever parameter you want \n",
    "model_params['max_iterations']=20000\n",
    "model_params['temperature']=1.266\n",
    "model_params['num_hidden_units']=64\n",
    "\n",
    "## set the model\n",
    "cebra_label=CEBRA(**model_params)\n",
    "# pippo=data_.get(train_data_[1])\n",
    "## fit model\n",
    "cebra_label.fit(data_.get(train_data_[0]),data_.get(train_data_[1]))\n",
    "\n",
    "### transform data (reduced dimension data)\n",
    "X_hat=cebra_label.transform(data_.get(transform_data_[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4051418-3b57-476f-93bb-07a551536135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n",
      "(9472,)\n",
      "Trial average shape: (148, 3)\n",
      "(148, 3)\n"
     ]
    }
   ],
   "source": [
    "##################################### PLOT\n",
    "c_s=\"maroon\"\n",
    "output_folder = default_output_dir\n",
    "results_list=[]\n",
    "#title='CEBRA-behavior trained with target label'\n",
    "ww=0\n",
    "y_dir_=y_dir_.flatten()\n",
    "#☻plot_embs_discrete(X_hat,y_dir_, title,trial_length, ww)\n",
    "\n",
    "const_len=True\n",
    "### parameters' values to name the plot   \n",
    "n_h_u=model_params['num_hidden_units']\n",
    "temp=model_params['temperature']\n",
    "iters=model_params['max_iterations']\n",
    "\n",
    "### shift or steps is the number of overlapping points \n",
    "title_=f\"K_CEBRA_cond1_shift_{overlap}_sum_nhu_{n_h_u}_temp{temp}_iters{iters}.html\"\n",
    "#results={}\n",
    "#results={}\n",
    "#results[title_]=X_hat\n",
    "\n",
    "#results['train final loss']=cebra_label.state_dict_['loss'][-1].numpy()\n",
    "#results['train loss']=cebra_label.state_dict_['loss'].numpy()\n",
    "\n",
    "plot_direction_averaged_embedding(\n",
    "            X_hat,\n",
    "            y_dir_,\n",
    "            original_label_order,\n",
    "            c_s,\n",
    "            output_folder,\n",
    "            title_,\n",
    "            trial_length,\n",
    "            constant_length=const_len,\n",
    "            ww=0,\n",
    "            label_swap_info=None\n",
    "        ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e86528-b74d-44a3-9ae5-caefa2cbdb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4addcee-f471-4d8c-9a5f-d3edaee180cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
