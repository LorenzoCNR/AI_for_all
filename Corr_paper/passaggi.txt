%%% abbiamo dati neurali e dati legati alle parole. 
%%% ora i dati neurali sono campionati a 512hz...se registriamo un minuto di conversazione abbiamo 512x60x(numero elettrodi)...fxTxN
% osservazioni
%%% le registrazioni vocali hanno frequenza maggiore e post prerocessing sono allineate(temporalmente) ai dati neurali da cui 
% avremo un subsampling...inotre,per ogni parola, si prende un intervallo intorno all'onset di piu/meno 4sec. (se la parola inizia a 5 secondi, si prende un intervallo da 1 a 9...le parole che sono agli estremi hanno un padding (replicato...usano quindi il primo o l'ultimo valore rispettivamente dopo o prima del padding stesso); ogni finestra di otto secondi viene segmentata in microfinestre (b=bins) di 62.5ms quindi 129 finestre per parola....P=#parole (ipotizziamo 150 parole al minuto).
Le parole sono inoltre proiettate con gpt2 in un emebedding di 1600 elementi (dimensione d) da cui ogni parole avra' una dimensione 129*1600 (la dimensione colonna si ripete per tutte le righe). 
La matrice X con tutte le parole del dialogo del minuto sara' 150x129x1600 (Pxbxd)....
A questo punto, si fanno Nxbins regressioni (una per elettrodo per bin)...quindi tante quanti sono gli elettrodi e quanti i lag. 
Con ogni regressione stimo per ogni parola l'effetto a quel bin una matrice di 1600 parametri...ogni peso rappresenta l'effetto di ciascuna feature di gpt2 sul segnaloe neurale in quel momento in quel punto del cervello. (Verosimilmente se un peso e' alto significa che che quella particolare dimensione dell'embedding di gpt2 ha un forte impatto sull'attivita' cerebrale in quel lag ed elettrodo.)... i pesi vengono poi ottimizzati con cross validation nested. 

